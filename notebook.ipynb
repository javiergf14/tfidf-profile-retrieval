{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile-based retrieval\n",
    "\n",
    "by Tolga Buz, Antonio Javier Gonz√°lez Ferrer and Aitor Palacios Cuesta.\n",
    "\n",
    "\n",
    "This script has been created using Jupyter Notebook and Python 3. Moreover, it requires the use and installation of the following libraries:\n",
    "* numpy\n",
    "* scipy\n",
    "* scikit-learn\n",
    "* tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Usually, when evaluating a information retrieval model, the basic concepts are the documents $d$ and a query $q$. The documents are the static elements, which express ideas about some topic in natural language. On the other hand, the queries represents a variable information need for documents pertaining to some topic. A document is represented by a set of index terms $k_i$. \n",
    "\n",
    "For our particular case, the <u>topics</u> represent conceptually the documents, since they are permanent along the model, and the <u>text snippets</u> are the queries, since we pretend to match to which profile is the query related. The users will have some topic preferences, and the goal is to provide the users the documents they are interested in. \n",
    "\n",
    "Note that in a real scenario the topics may be created based on a long list of specific terms. These index terms may be built from documents that we are sure that represent such topic. For instance, the topics for the term `sport` may be extracted from sport magazines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Defining topics.\n",
    "# Each topic is treated conceptually as a document.\n",
    "topic_music    = [\"music\", \"sound\", \"song\", \"songs\", \"Taylor\", \"Swift\", \"Justin\", \"Bieber\", \"Mozart\", \"pop\", \"stars\", \"singing\"]\n",
    "topic_film     = [\"movie\", \"movies\", \"film\", \"Tarantino\", \"Pulp\", \"Fiction\", \"actor\", \"director\"]\n",
    "topic_sports   = [\"football\", \"star\", \"soccer\", \"goal\", \"messi\", \"jogging\", \"swimming\", \"fitness\"]\n",
    "topic_cars     = [\"Ferrari\", \"Lamborghini\", \"car\", \"speed\", \"high\", \"enzo\", \"aventador\", \"driving\"]\n",
    "topic_politics = [\"politics\", \"economics\", \"trump\", \"stock\", \"market\" ]\n",
    "\n",
    "# List of topics.\n",
    "topics_names = [\"topic_music\", \"topic_film\", \"topic_sports\", \"topic_cars\", \"topic_politics\"]\n",
    "topics_values = [topic_music, topic_film, topic_sports, topic_cars, topic_politics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We match the topics to some fictitious users. For instance, `user1` likes cars, sports and films; `user2` prefers music and politics; and `user3` loves films:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Defining the users\n",
    "user1  = [\"topic_cars\", \"topic_sports\", \"topic_film\"]\n",
    "user2  = [\"topic_music\", \"topic_politics\"]\n",
    "user3  = [\"topic_film\"]\n",
    "users = {\"user1\": user1,\n",
    "         \"user2\": user2,\n",
    "         \"user3\": user3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, the users can receive any kind of text snippets and such text snippet will be classified according their topics. However, since this is a toy example to assimilate concepts, and the golden standard of terms in the topics is small, we need to define manually the queries using related terms from the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Loading in text snippets that need to be classified.\n",
    "# Every text snippet only has 1 topic per definition.\n",
    "# Each text snippet is a query\n",
    "text_snippets = [\"Jogging is one of the best sports, but I love football\", \n",
    "                 \"Politics news are strongly affecting economics.\",\n",
    "                 \"Tarantino is a bad actor, but a good director.\", \n",
    "                 \"Ferrari Enzo is faster than Lamborghini Aventador, though its music accessories have more quality.\", \n",
    "                 \"Ferrari builds the best high speed cars.\",\n",
    "                 \"Football star Messi is also doing jogging, swimming and fitness to stay in shape.\",\n",
    "                 \"Pulp fiction is one of the best movies ever made.\",\n",
    "                 \"Taylor Swift and Justin Bieber are pop stars.\",\n",
    "                 \"Mozart is much better than Justin Bieber.\",\n",
    "                 \"Many people do not like to hear Taylor Swift singing in spite of she might be married with Tarantino.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to represent both documents and queries as a bag of words, where the corresponding document or query is represented as a column in a matrix where terms correspond to the rows, and their corresponding cell value is the numberof times that term appears in the text.  After forming this matrix,  that cell number is used to calculate a new score for the term in that text.  Then, each column will representthe vector of the corresponding topic or snippet.  The score number is calculated usingthe  `tf-idf`  measure  that  we  found  appropriate. \n",
    "\n",
    "The standard scheme used along this documents is to use the inverse document frequency in the queries (`tfidf` object) but no to use it in the documents (`tf` object). Both queries and documents have logarithmic tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', \n",
    "                     strip_accents='unicode', # Remove accents during the preprocessing step\n",
    "                     stop_words = 'english', # Eliminate stop words from English\n",
    "                     lowercase=True, # Convert all characters to lowercase before tokenizing\n",
    "                     use_idf=False, # Disable the inverse-document-frequency reweightening\n",
    "                     sublinear_tf = True, # Logarithmic tf\n",
    "                     norm='l2') # Normalization\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', \n",
    "                     strip_accents='unicode', \n",
    "                     stop_words = 'english', \n",
    "                     lowercase=True, \n",
    "                     use_idf=True, # Enable inverse-document-frequency reweightening\n",
    "                     smooth_idf = True, # Smooth idf weights by adding one to document frequencies. Prevents zero divisions.\n",
    "                     sublinear_tf = True,\n",
    "                     norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we fit the topcics with the logarithmic tf approach. Then, we transform the topics to the matrix of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Represent each document as a weighted tf-idf vector\n",
    "topics_text = list(map(lambda x: \",\".join(x), topics_values))\n",
    "tf_matrix = tf.fit_transform(topics_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we fit the text snippets with the logarithmic tf and idf approach, getting also the corresponding matrix of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Represent the query as a weighted tf-idf vector\n",
    "tfidf_matrix = tfidf.fit_transform(topics_text)\n",
    "tfidf_query = tfidf.transform(text_snippets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we apply the cosine similarity between the two matrices. Since we have normalized both documents and queries, the cosine similarity is simply the dot product between the matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the cosine similarity score for the query vector and each document vector.\n",
    "# Note: Cosine for length-normalized vectors is simply the dot product (or scalar product).\n",
    "cosine_similarity = (tf_matrix * tfidf_query.T).A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let us visualize the cosine similarity matrix. It represents, for each of the documents (columns), which are the most similar topics (rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|          |   text1 |   text2 |   text3 |   text4 |   text5 |   text6 |   text7 |   text8 |   text9 |   text10 |\n",
      "|:---------|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|--------:|---------:|\n",
      "| music    |    0.00 |    0.00 |    0.00 |    0.13 |    0.00 |    0.00 |    0.00 |    0.71 |    0.50 |     0.43 |\n",
      "| films    |    0.00 |    0.00 |    0.61 |    0.00 |    0.00 |    0.00 |    0.61 |    0.00 |    0.00 |     0.18 |\n",
      "| sports   |    0.50 |    0.00 |    0.00 |    0.00 |    0.00 |    0.87 |    0.00 |    0.00 |    0.00 |     0.00 |\n",
      "| cars     |    0.00 |    0.00 |    0.00 |    0.63 |    0.61 |    0.00 |    0.00 |    0.00 |    0.00 |     0.00 |\n",
      "| politics |    0.00 |    0.63 |    0.00 |    0.00 |    0.00 |    0.00 |    0.00 |    0.00 |    0.00 |     0.00 |\n"
     ]
    }
   ],
   "source": [
    "headers = ['text1', 'text2', 'text3', 'text4', 'text5', 'text6', 'text7', 'text8', 'text9', 'text10']\n",
    "body = np.append(np.array([[\"music\"],[\"films\"],[\"sports\"],[\"cars\"],[\"politics\"]])\n",
    "                 , cosine_similarity, axis=1)\n",
    "print(tabulate(body, headers=headers, tablefmt='pipe', floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our solution proposes a unique topic per document. Therefore, let us select the max value for each of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Categorization of the text_snippets\n",
    "# Rank documents with respect to the query by score (the higher, the better)\n",
    "# Return best ones.\n",
    "categories = np.argmax(cosine_similarity, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `categories` vector contains the indeces of the matched topics per each of the text snippets. The rest of the notebook is straightforward: see the topics for each of the users, and give them the text snippets that matches their profiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Assign text_snippets to users\n",
    "user1_result = []\n",
    "user2_result = []\n",
    "user3_result = []\n",
    "\n",
    "for text_id, category_id in enumerate(categories):\n",
    "    category = topics_names[category_id]\n",
    "    if category in user1:\n",
    "        user1_result.append(text_id)\n",
    "    if category in user2:\n",
    "        user2_result.append(text_id)\n",
    "    if category in user3:\n",
    "        user3_result.append(text_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conclude, we show which of the initial text snippets are matched to which user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "user1 profile: ['topic_cars', 'topic_sports', 'topic_film']\n",
      "\n",
      "Texts:\n",
      "Jogging is one of the best sports, but I love football\n",
      "Tarantino is a bad actor, but a good director.\n",
      "Ferrari Enzo is faster than Lamborghini Aventador, though its music accessories have more quality.\n",
      "Ferrari builds the best high speed cars.\n",
      "Football star Messi is also doing jogging, swimming and fitness to stay in shape.\n",
      "Pulp fiction is one of the best movies ever made.\n",
      "\n",
      "\n",
      "\n",
      "user2 profile: ['topic_music', 'topic_politics']\n",
      "\n",
      "Texts:\n",
      "Politics news are strongly affecting economics.\n",
      "Taylor Swift and Justin Bieber are pop stars.\n",
      "Mozart is much better than Justin Bieber.\n",
      "Many people do not like to hear Taylor Swift singing in spite of she might be married with Tarantino.\n",
      "\n",
      "\n",
      "\n",
      "user3 profile: ['topic_film']\n",
      "\n",
      "Texts:\n",
      "Tarantino is a bad actor, but a good director.\n",
      "Pulp fiction is one of the best movies ever made.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_text_snippets(user, name):\n",
    "    \"\"\"Function to print the users and their matched topics\"\"\"\n",
    "    print(\"\\n\" + name + \" profile: \" + str(users[name]))\n",
    "    print(\"\\nTexts:\")\n",
    "    for text in list(map(lambda x: text_snippets[x], user)):\n",
    "        print(text)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "print_text_snippets(user1_result, \"user1\")\n",
    "print_text_snippets(user2_result, \"user2\")\n",
    "print_text_snippets(user3_result, \"user3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
